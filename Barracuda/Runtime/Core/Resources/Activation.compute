#pragma kernel Abs_Flat
#pragma kernel Abs_FlatStrict
#pragma kernel Abs_Loop
#pragma kernel Neg_Flat
#pragma kernel Neg_FlatStrict
#pragma kernel Neg_Loop
#pragma kernel Ceil_Flat
#pragma kernel Ceil_FlatStrict
#pragma kernel Ceil_Loop
#pragma kernel Floor_Flat
#pragma kernel Floor_FlatStrict
#pragma kernel Floor_Loop
#pragma kernel Reciprocal_Flat
#pragma kernel Reciprocal_FlatStrict
#pragma kernel Reciprocal_Loop
#pragma kernel Relu_Flat
#pragma kernel Relu_FlatStrict
#pragma kernel Relu_Loop
#pragma kernel Relu6_Flat
#pragma kernel Relu6_FlatStrict
#pragma kernel Relu6_Loop
#pragma kernel Selu_Flat
#pragma kernel Selu_FlatStrict
#pragma kernel Selu_Loop
#pragma kernel Tanh_Flat
#pragma kernel Tanh_FlatStrict
#pragma kernel Tanh_Loop
#pragma kernel Sin_Flat
#pragma kernel Sin_FlatStrict
#pragma kernel Sin_Loop
#pragma kernel Cos_Flat
#pragma kernel Cos_FlatStrict
#pragma kernel Cos_Loop
#pragma kernel Swish_Flat
#pragma kernel Swish_FlatStrict
#pragma kernel Swish_Loop
#pragma kernel Sigmoid_Flat
#pragma kernel Sigmoid_FlatStrict
#pragma kernel Sigmoid_Loop
#pragma kernel Elu_Flat
#pragma kernel Elu_FlatStrict
#pragma kernel Elu_Loop
#pragma kernel LeakyRelu_Flat
#pragma kernel LeakyRelu_FlatStrict
#pragma kernel LeakyRelu_Loop
#pragma kernel Exp_Flat
#pragma kernel Exp_FlatStrict
#pragma kernel Exp_Loop
#pragma kernel Log_Flat
#pragma kernel Log_FlatStrict
#pragma kernel Log_Loop
#pragma kernel Sqrt_Flat
#pragma kernel Sqrt_FlatStrict
#pragma kernel Sqrt_Loop
#pragma kernel Pow_Flat
#pragma kernel Pow_FlatStrict
#pragma kernel Pow_Loop
#pragma kernel LogicalNot_Flat
#pragma kernel LogicalNot_FlatStrict
#pragma kernel LogicalNot_Loop
#pragma kernel Clip_Flat
#pragma kernel Clip_FlatStrict
#pragma kernel Clip_Loop

#pragma kernel PRelu_Flat
#pragma kernel PRelu_Loop

/*
Relu_Flat (NEW) vs Relu_Nyxc+Relu_CNyx+Relu
Compute Precompiled

VGG@1
<<<Exec #128:  59.6 ms, cpu: .9 ms, avg:  62.4 ms, result:OK    <--- NEW!
<<<Exec #128:  63.6 ms, cpu: .9 ms, avg:  64.0 ms, result:OK

VGG@4
<<<Exec #16: 276.7 ms, cpu: .9 ms, avg: 272.8 ms, result:OK     <--- NEW!
<<<Exec #16: 297.5 ms, cpu: .9 ms, avg: 274.4 ms, result:OK

RES@1
<<<Exec #100:  82.2 ms, cpu: 22.2 ms, avg:  81.0 ms, result:OK  <--- NEW!
<<<Exec #100:  82.1 ms, cpu: 22.5 ms, avg:  85.4 ms, result:OK

PPO_2@256
<<<Exec #200:  10.3 ms, cpu: 7.6 ms, avg:  11.9 ms, result:OK   <--- NEW!
<<<Exec #200:  10.9 ms, cpu: 8.3 ms, avg:  12.3 ms, result:OK

PPO_CNN@256
<<<Exec #100:  60.6 ms, cpu: 62.3 ms, avg:  65.6 ms, result:OK  <--- NEW!
<<<Exec #100:  72.6 ms, cpu: 62.7 ms, avg:  66.0 ms, result:OK
*/

#pragma kernel Relu_NHWC CHANNELS_FIRST=0
#pragma kernel Relu_NCHW CHANNELS_FIRST=1
#pragma kernel Relu_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Relu_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Relu_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Relu_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Relu6_NHWC CHANNELS_FIRST=0
#pragma kernel Relu6_NCHW CHANNELS_FIRST=1
#pragma kernel Relu6_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Relu6_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Relu6_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Relu6_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel PRelu_NHWC CHANNELS_FIRST=0
#pragma kernel PRelu_NCHW CHANNELS_FIRST=1
#pragma kernel PRelu_CNyx2_NHWC CHANNELS_FIRST=0
//#pragma kernel PRelu_CNyx2_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Selu_NHWC CHANNELS_FIRST=0
#pragma kernel Selu_NCHW CHANNELS_FIRST=1
#pragma kernel Selu_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Selu_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Selu_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Selu_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Tanh_NHWC CHANNELS_FIRST=0
#pragma kernel Tanh_NCHW CHANNELS_FIRST=1
#pragma kernel Tanh_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Tanh_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Tanh_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Tanh_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Sin_NHWC CHANNELS_FIRST=0
#pragma kernel Sin_NCHW CHANNELS_FIRST=1
#pragma kernel Sin_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Sin_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Sin_Nyxc_NHWC CHANNELS_FIRST=0
#pragma kernel Sin_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Cos_NHWC CHANNELS_FIRST=0
#pragma kernel Cos_NCHW CHANNELS_FIRST=1
#pragma kernel Cos_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Cos_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Cos_Nyxc_NHWC CHANNELS_FIRST=0
#pragma kernel Cos_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Swish_NHWC CHANNELS_FIRST=0
#pragma kernel Swish_NCHW CHANNELS_FIRST=1
#pragma kernel Swish_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Swish_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Swish_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Swish_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Sigmoid_NHWC CHANNELS_FIRST=0
#pragma kernel Sigmoid_NCHW CHANNELS_FIRST=1
#pragma kernel Sigmoid_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Sigmoid_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Sigmoid_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Sigmoid_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Elu_NHWC CHANNELS_FIRST=0
#pragma kernel Elu_NCHW CHANNELS_FIRST=1
#pragma kernel Elu_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Elu_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Elu_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Elu_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel LeakyRelu_NHWC CHANNELS_FIRST=0
#pragma kernel LeakyRelu_NCHW CHANNELS_FIRST=1
#pragma kernel LeakyRelu_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel LeakyRelu_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel LeakyRelu_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel LeakyRelu_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Exp_NHWC CHANNELS_FIRST=0
#pragma kernel Exp_NCHW CHANNELS_FIRST=1
#pragma kernel Exp_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Exp_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Exp_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Exp_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Log_NHWC CHANNELS_FIRST=0
#pragma kernel Log_NCHW CHANNELS_FIRST=1
#pragma kernel Log_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Log_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Log_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Log_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Sqrt_NHWC CHANNELS_FIRST=0
#pragma kernel Sqrt_NCHW CHANNELS_FIRST=1
#pragma kernel Sqrt_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Sqrt_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Sqrt_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Sqrt_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Pow_NHWC CHANNELS_FIRST=0
#pragma kernel Pow_NCHW CHANNELS_FIRST=1
#pragma kernel Pow_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Pow_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Pow_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Pow_Nyxc_NCHW CHANNELS_FIRST=1
#pragma kernel Softmax_NHWC CHANNELS_FIRST=0
#pragma kernel Softmax_NCHW CHANNELS_FIRST=1
#pragma kernel LogSoftmax_NHWC CHANNELS_FIRST=0
#pragma kernel LogSoftmax_NCHW CHANNELS_FIRST=1
#pragma kernel Clip_NHWC CHANNELS_FIRST=0
#pragma kernel Clip_NCHW CHANNELS_FIRST=1
#pragma kernel Clip_CNyx_NHWC CHANNELS_FIRST=0
//#pragma kernel Clip_CNyx_NCHW CHANNELS_FIRST=1 //This kernel require NHWC by design
#pragma kernel Clip_Nyxc_NHWC CHANNELS_FIRST=0
//#pragma kernel Clip_Nyxc_NCHW CHANNELS_FIRST=1

#include "Tensor.cginc"

TENSOR_DECL(X)
TENSOR_DECL_RW(O)

float _Alpha;
float _Beta;
uint _LoopStride;

//DISPATCH ARGS(O.length, 1, 1);
#define FLAT_ACTIVATION(name, op_name) \
void name##_Flat(uint3 dispatchThreadID : SV_DispatchThreadID)\
{\
    TENSOR_ARGS2(X, O);\
\
    uint i = dispatchThreadID.x;\
    if (i >= O.GetLength()) return;\
\
    float v = X.FastGet(i);\
    v = op_name (v);\
    O.FastSet(i, v);\
}

//DISPATCH ARGS(O.length/2, 1, 1)
#define FLAT_ACTIVATION_STRICT(name, op_name) \
void name##_FlatStrict(uint3 groupId : SV_GroupID, uint3 groupThreadId : SV_GroupThreadID)\
{\
    TENSOR_ARGS2(X, O);\
\
    uint numThreadsPerTG = NUMTHREAD(512, 128, 64);\
    uint i1 = (groupId.x * 2 + 0) * numThreadsPerTG + groupThreadId.x;\
	uint i2 = (groupId.x * 2 + 1) * numThreadsPerTG + groupThreadId.x;\
    float v1 = X.FastGet(i1);\
	float v2 = X.FastGet(i2);\
    v1 = op_name (v1);\
	v2 = op_name (v2);\
    O.FastSet(i1, v1);\
	O.FastSet(i2, v2);\
}

//DISPATCH ARGS(O.length, 1, 1);
#define LOOP_ACTIVATION(name, op_name) \
void name##_Loop(uint3 dispatchThreadID : SV_DispatchThreadID)\
{\
    TENSOR_ARGS2(X, O);\
\
    uint i = dispatchThreadID.x;\
    uint len = O.GetLength();\
\
    while (i < len) {\
        float v = X.FastGet(i); \
        v = op_name (v); \
        O.FastSet(i, v); \
        i += _LoopStride; \
    }\
}

#define ACTIVATION(name, op_name) \
NUMTHREADS((512,1,1), (128,1,1), (64,1,1))\
FLAT_ACTIVATION(name, op_name)\
NUMTHREADS((512,1,1), (128,1,1), (64,1,1))\
FLAT_ACTIVATION_STRICT(name, op_name)\
NUMTHREADS((512,1,1), (128,1,1), (64,1,1))\
LOOP_ACTIVATION(name, op_name)

float relu(float v)
{
    return max(v, 0.0f);
}

float relu6(float v)
{
    return min(max(v, 0.0f), 6.0f);
}

float swish(float v)
{
    return v / (1.f + exp(-v));
}

float prelu(float v, float alpha)
{
	return max(v, 0.0f) + alpha * min(v, 0.0f);
}

float selu(float v)
{
	return _Beta * (max(v, 0.0f) + min(_Alpha * (exp(v) - 1.0f), 0.0f));
}

float sigmoid(float v)
{
    return rcp(1.f + exp(-v));
}

float elu(float v)
{
    return (v <= 0.f) ? _Alpha * (exp(v) - 1.f) : v;
}

float lrelu(float v)
{
    return max(v, _Alpha * v);
}

float signed_pow(float f)
{
	return pow(abs(f), _Alpha);
}

float logical_not(float v)
{
    return (v == 0.0f) ? 1.0f : 0.0f;
}

float neg(float v)
{
    return -v;
}

float tanh_safe(float x)
{
    return tanh(clamp(x,-16.0f,16.0f));//clamp to avoid NaNs for large values.
}

float activation_clip(float v)
{
	return clamp(v, _Alpha, _Beta);
}


ACTIVATION(Abs, abs)
ACTIVATION(Neg, neg)
ACTIVATION(Ceil, ceil)
ACTIVATION(Floor, floor)
ACTIVATION(Reciprocal, rcp)
ACTIVATION(Relu, relu)
ACTIVATION(Relu6, relu6)
ACTIVATION(Tanh, tanh_safe)
ACTIVATION(Sin, sin)
ACTIVATION(Cos, cos)
ACTIVATION(Sigmoid, sigmoid)
ACTIVATION(Swish, swish)
ACTIVATION(Elu, elu)
ACTIVATION(Selu, selu)
ACTIVATION(LeakyRelu, lrelu)
ACTIVATION(Exp, exp)
ACTIVATION(Log, log)
ACTIVATION(Sqrt, sqrt)
ACTIVATION(Pow, signed_pow)
ACTIVATION(LogicalNot, logical_not)
ACTIVATION(Clip, activation_clip)

// -------------------

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Relu)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint x = dispatchThreadID.y;
    uint y = dispatchThreadID.z;

    if (c >= O.channels) return;
    if (x >= O.width) return;
    if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = relu(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Relu6)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint x = dispatchThreadID.y;
    uint y = dispatchThreadID.z;

    if (c >= O.channels) return;
    if (x >= O.width) return;
    if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = relu6(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4, 8, 8), (4, 8, 4), (4, 4, 4))
void KERNEL_FUNC(Selu)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.width, O.height);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;
	uint x = dispatchThreadID.y;
	uint y = dispatchThreadID.z;

	if (c >= O.channels) return;
	if (x >= O.width) return;
	if (y >= O.height) return;

	for (uint n = 0; n < X.batch; ++n)
	{
		float v = X.Get(n, y, x, c);
		v = selu(v);
		O.Set(n, y, x, c, v);
	}
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Tanh)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = tanh_safe(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Sin)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = sin(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Cos)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = cos(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
 void KERNEL_FUNC(Sigmoid)(uint3 dispatchThreadID : SV_DispatchThreadID)
 {
     //DISPATCH ARGS(O.channels, O.width, O.height);
     TENSOR_ARGS2(X, O);

     uint c = dispatchThreadID.x;
     uint x = dispatchThreadID.y;
     uint y = dispatchThreadID.z;

     if (c >= O.channels) return;
     if (x >= O.width) return;
     if (y >= O.height) return;

     for (uint n = 0; n < X.batch; ++n)
     {
         float v = X.Get(n, y, x, c);
         v = sigmoid(v);
         O.Set(n, y, x, c, v);
     }
 }

 NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Swish)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint x = dispatchThreadID.y;
    uint y = dispatchThreadID.z;

    if (c >= O.channels) return;
    if (x >= O.width) return;
    if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = swish(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Elu)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = elu(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(LeakyRelu)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = lrelu(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Exp)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = exp(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Log)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = log(v);
        O.Set(n, y, x, c, v);
    }
}

NUMTHREADS((4, 8, 8), (4, 8, 4), (4, 4, 4))
void KERNEL_FUNC(Sqrt)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.width, O.height);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
	if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

	for (uint n = 0; n < X.batch; ++n)
	{
		float v = X.Get(n, y, x, c);
		v = sqrt(v);
		O.Set(n, y, x, c, v);
	}
}

NUMTHREADS((4,8,8), (4,8,4), (4,4,4))
void KERNEL_FUNC(Pow)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.width, O.height);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;    uint x = dispatchThreadID.y;    uint y = dispatchThreadID.z;
    if (c >= O.channels) return;    if (x >= O.width) return;        if (y >= O.height) return;

    for (uint n = 0; n < X.batch; ++n)
    {
        float v = X.Get(n, y, x, c);
        v = signed_pow(v);
        O.Set(n, y, x, c, v);
    }
}


NUMTHREADS((4, 8, 8), (4, 8, 4), (4, 4, 4))
void KERNEL_FUNC(Clip)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.width, O.height);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;
	uint x = dispatchThreadID.y;
	uint y = dispatchThreadID.z;

	if (c >= O.channels) return;
	if (x >= O.width) return;
	if (y >= O.height) return;

	for (uint n = 0; n < X.batch; ++n)
	{
		float v = X.Get(n, y, x, c);
		v = activation_clip(v);
		O.Set(n, y, x, c, v);
	}
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Relu_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = relu(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Relu_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = relu(v);
    O.Set(n, y, x, c, v);
}


NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Relu6_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = relu6(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Relu6_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = relu6(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16, 16, 1), (16, 8, 1), (16, 4, 1))
void KERNEL_FUNC(Selu_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;
	uint nyx = dispatchThreadID.y;

	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (c >= X.channels) return;
	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = selu(v);
	O.Set(n, y, x, c, v);
}

NUMTHREADS((512, 1, 1), (128, 1, 1), (64, 1, 1))
void KERNEL_FUNC(Selu_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
	TENSOR_ARGS2(X, O);

	uint nyxc = dispatchThreadID.x;

	uint c = nyxc % X.channels;
	uint nyx = nyxc / X.channels;
	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = selu(v);
	O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Tanh_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = tanh_safe(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Sin_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = sin(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Cos_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = cos(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Tanh_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = tanh_safe(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Sin_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.batch * O.height * O.width * O.channels, 1, 1)
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = sin(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Cos_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    DISPATCH_ARGS(O.batch * O.height * O.width * O.channels, 1, 1)
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = cos(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Sigmoid_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = sigmoid(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Sigmoid_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = sigmoid(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Swish_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = swish(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Swish_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = swish(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Elu_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = elu(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Elu_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = elu(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(LeakyRelu_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = lrelu(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(LeakyRelu_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = lrelu(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Exp_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = exp(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Exp_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = exp(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Log_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = log(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Log_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = log(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16, 16, 1), (16, 8, 1), (16, 4, 1))
void KERNEL_FUNC(Sqrt_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;
	uint nyx = dispatchThreadID.y;

	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (c >= X.channels) return;
	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = sqrt(v);
	O.Set(n, y, x, c, v);
}

NUMTHREADS((512, 1, 1), (128, 1, 1), (64, 1, 1))
void KERNEL_FUNC(Sqrt_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
	TENSOR_ARGS2(X, O);

	uint nyxc = dispatchThreadID.x;

	uint c = nyxc % X.channels;
	uint nyx = nyxc / X.channels;
	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = sqrt(v);
	O.Set(n, y, x, c, v);
}

NUMTHREADS((16,16,1), (16,8,1), (16,4,1))
void KERNEL_FUNC(Pow_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
    TENSOR_ARGS2(X, O);

    uint c = dispatchThreadID.x;
    uint nyx = dispatchThreadID.y;

    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (c >= X.channels) return;
    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = signed_pow(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((512,1,1), (128,1,1), (64,1,1))
void KERNEL_FUNC(Pow_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
    TENSOR_ARGS2(X, O);

    uint nyxc = dispatchThreadID.x;

    uint c = nyxc % X.channels;
    uint nyx = nyxc / X.channels;
    uint x = nyx % X.width;
    uint ny = nyx / X.width;
    uint y = ny % X.height;
    uint n = ny / X.height;

    if (n >= X.batch) return;

    float v = X.Get(n, y, x, c);
    v = signed_pow(v);
    O.Set(n, y, x, c, v);
}

NUMTHREADS((16, 16, 1), (16, 8, 1), (16, 4, 1))
void KERNEL_FUNC(Clip_CNyx)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
	TENSOR_ARGS2(X, O);

	uint c = dispatchThreadID.x;
	uint nyx = dispatchThreadID.y;

	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (c >= X.channels) return;
	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = activation_clip(v);
	O.Set(n, y, x, c, v);
}

NUMTHREADS((512, 1, 1), (128, 1, 1), (64, 1, 1))
void KERNEL_FUNC(Clip_Nyxc)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.batch * O.height * O.width * O.channels, 1, 1);
	TENSOR_ARGS2(X, O);

	uint nyxc = dispatchThreadID.x;

	uint c = nyxc % X.channels;
	uint nyx = nyxc / X.channels;
	uint x = nyx % X.width;
	uint ny = nyx / X.width;
	uint y = ny % X.height;
	uint n = ny / X.height;

	if (n >= X.batch) return;

	float v = X.Get(n, y, x, c);
	v = activation_clip(v);
	O.Set(n, y, x, c, v);
}


NUMTHREADS((64,4,1), (64,2,1), (64,1,1))
void KERNEL_FUNC(Softmax)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    //DISPATCH ARGS(O.flatWidth, O.flatHeight, 1);
    TENSOR_ARGS2(X, O);

    uint x = dispatchThreadID.x;
    uint y = dispatchThreadID.y;

    if (x >= O.GetFlatWidth()) return;
    if (y >= O.GetFlatHeight()) return;

    float maxV = -FLT_MAX;
    uint i;
    for (i = 0; i < X.GetFlatWidth(); ++i)
    {
        float v = X.Get(y, i);
        if (v > maxV)
            maxV = v;
    }

    float acc = 0.0f;
    for (i = 0; i < X.GetFlatWidth(); ++i)
    {
        float v = X.Get(y, i);
        acc += exp(v - maxV);
    }

    float v = X.Get(y, x);
    v = exp(v - maxV) / acc;
    O.Set(y, x, v);
}

// log(exp(x)/S_i(exp(xi)) = log(exp(x)) - log(S_i(exp(xi)))
//                         = exp(x) - log(S_i(exp(xi)))
NUMTHREADS((64, 4, 1), (64, 2, 1), (64, 1, 1))
void KERNEL_FUNC(LogSoftmax)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.flatWidth, O.flatHeight, 1);
	TENSOR_ARGS2(X, O);

	uint x = dispatchThreadID.x;
	uint y = dispatchThreadID.y;

	if (x >= O.GetFlatWidth()) return;
	if (y >= O.GetFlatHeight()) return;

	float maxV = -FLT_MAX;
	uint i;
	for (i = 0; i < X.GetFlatWidth(); ++i)
	{
		float v = X.Get(y, i);
		if (v > maxV)
			maxV = v;
	}

	float acc = 0.0f;
	for (i = 0; i < X.GetFlatWidth(); ++i)
	{
		float v = X.Get(y, i);
		acc += exp(v - maxV);
	}

	float v = X.Get(y, x);
	v = (v - maxV) - log(acc);
	O.Set(y, x, v);
}

TENSOR_DECL(W)
TENSOR_DECL(B)
TENSOR_DECL(WBK)

NUMTHREADS((4, 8, 8), (4, 8, 4), (4, 4, 4))
void KERNEL_FUNC(PRelu)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.width, O.height);
	TENSOR_ARGS3(X, W, O);

	uint c = dispatchThreadID.x;
	uint x = dispatchThreadID.y;
	uint y = dispatchThreadID.z;

	if (c >= O.channels) return;
	if (x >= O.width) return;
	if (y >= O.height) return;

	float slope = W.Get(0, 0, 0, c);

	for (uint n = 0; n < X.batch; ++n)
	{
		float slope = W.BroadcastGet(n, y, x, c);
		float v = X.Get(n, y, x, c);
		v = prelu(v,slope);
		O.Set(n, y, x, c, v);
	}

}


NUMTHREADS((256, 1, 1), (128, 1, 1), (64, 1, 1))
void PRelu_Flat(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.length, 1, 1);
	TENSOR_ARGS3(X, W, O);

	uint i = dispatchThreadID.x;
	if (i >= O.GetLength()) return;

	float slope = W.FastBroadcastGet(i);
	float v = X.FastGet(i);
	v = prelu(v, slope);
	O.FastSet(i, v);

}

NUMTHREADS((256, 1, 1), (128, 1, 1), (64, 1, 1))
void PRelu_Loop(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.length, 1, 1);
	TENSOR_ARGS3(X, W, O);

	uint i = dispatchThreadID.x;
	uint len = O.GetLength();

	while (i < len)
	{
		float slope = W.FastBroadcastGet(i);
		float v = X.FastGet(i);
		v = prelu(v, slope);
		O.FastSet(i, v);

		i += _LoopStride;
	}

}

NUMTHREADS((32, 4, 1), (32, 2, 1), (16, 2, 1))
void KERNEL_FUNC(PRelu_CNyx2)(uint3 dispatchThreadID : SV_DispatchThreadID)
{
	//DISPATCH ARGS(O.channels, O.batch * O.height * O.width, 1);
	TENSOR_ARGS3(X, W, O);

	uint c = dispatchThreadID.x;
	uint i = dispatchThreadID.y * X.channels + c;

	if (c >= X.channels) return;
	if (i >= X.GetLength()) return;

	float slope = W.FastBroadcastGet(i);
	float v = X.FastGet(i);
	v = prelu(v, slope);
	O.FastSet(i, v);

}
